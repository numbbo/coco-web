---
title: "COCO: COmparing Continuous Optimizers"
---


![](/images/coco.png){width=90% fig-align="center" .lightbox}

# A Short Introduction to COCO

COCO is a platform for a systematic and sound comparison of (mainly continuous and mixed) optimization algorithms.
COCO provides implementations of

- benchmark function testbeds, 
- experimentation templates which are easy to parallelize
- tools for processing and visualization of the data generated by one or several optimizers

For a general introduction to the COCO software and its underlying concepts of performance assessment, see @hansen2021.
For getting started see [Getting Started](getting-started/index.qmd).

# Related links
* [Getting Started](getting-started/index.qmd)
* <a href="https://numbbo.github.io/data-archive">
  Data archive</a> of all officially registered benchmark experiments (also accessible via
  the <a href="https://pypi.org/project/cocopp">postprocess module</a>)
* [Postprocessed data][ppdata] of these archives for browsing
<li><a href="https://github.com/numbbo/coco/blob/master/howtos/publish-a-dataset-howto.md">
  How to submit a data set</a>
</li>
* [How to create and use COCO data archives](https://github.com/numbbo/coco-postprocess/blob/main/src/cocopp/archiving.py)
with the `cocopp.archiving` Python module
* [Source code (developer) page on Github](https://github.com/numbbo/coco)
<li>Get news about COCO by <a href="http://numbbo.github.io/register">registering here</a>
</li>
<li>
  To visit the old COCO webpage, see the <a href="https://web.archive.org/web/20210504150230/https://coco.gforge.inria.fr/">Internet Archive</a>
</li>

[ppdata]: https://numbbo.github.io/ppdata-archive

# Citation and References

You may cite this work in a scientific context as

> Hansen, N., A. Auger, R. Ros, O. Mersmann, T. Tušar, D. Brockhoff. [COCO: A Platform for Comparing Continuous Optimizers in a Black-Box Setting](https://doi.org/10.1080/10556788.2020.1808977), _Optimization Methods and Software_, 36(1), pp. 114-144, 2021. [[pdf](https://www.tandfonline.com/eprint/DQPF7YXFJVMTQBH8NKR8/pdf?target=10.1080/10556788.2020.1808977), [arXiv](https://arxiv.org/abs/1603.08785)]

```bibtex
@article{hansen2021coco,
  author = {Hansen, N. and Auger, A. and Ros, R. and Mersmann, O. and Tu{\v s}ar, T. and Brockhoff, D.},
  title = {{COCO}: A Platform for Comparing Continuous Optimizers in a Black-Box Setting},
  journal = {Optimization Methods and Software},
  doi = {https://doi.org/10.1080/10556788.2020.1808977},
  pages = {114--144},
  issue = {1},
  volume = {36},
  year = 2021
}
```

The COCO platform has been used for the Black-Box-Optimization-Benchmarking (BBOB) workshops that took place during the GECCO conference in 2009, 2010, 2012, 2013, 2015 -- 2019, and 2021 -- 2023.
It was also used at the IEEE Congress on Evolutionary Computation (CEC’2015) in Sendai, Japan.

The COCO experiment source code has been rewritten in the years 2014-2015 and the current production code is available on our COCO Github page.
The old code is still available here and shall be used for experiments on the noisy test suite until this test suite will be available in the new code as well.
